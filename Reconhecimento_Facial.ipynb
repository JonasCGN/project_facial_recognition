{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMULLXqpYfRuaCJALKcly+A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JonasCGN/project_facial_recognition/blob/main/Reconhecimento_Facial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#VisÃ£o Computacional: O Guia Completo - Reconhecimento Facial"
      ],
      "metadata": {
        "id": "Za7QeSRp8oLN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6oNYdyU8i7n",
        "outputId": "ac3c42af-8ca4-4a35-fe49-9a9a089f066f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-contrib-python==4.5.5.64 in /usr/local/lib/python3.10/dist-packages (4.5.5.64)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-contrib-python==4.5.5.64) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-contrib-python==4.5.5.64"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Carregamento da base de dados"
      ],
      "metadata": {
        "id": "2_qAHS1H8_l-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import cv2\n",
        "print(cv2.__version__)\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynmtn6s39E6o",
        "outputId": "093f8d71-497d-4a5e-ffd6-be148e8fa08a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.5.5\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "path = '/content/drive/MyDrive/Visao_Computacional_Guia_Completo/Datasets/yalefaces.zip'\n",
        "zip_objetc = zipfile.ZipFile(file=path, mode='r')\n",
        "zip_objetc.extractall('./')\n",
        "zip_objetc.close()"
      ],
      "metadata": {
        "id": "2B92Lpc59tW2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pre-processamento das imagens"
      ],
      "metadata": {
        "id": "_L2BP24C-ERy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir('/content/yalefaces/train'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUi1eD9s-Slt",
        "outputId": "3a324528-d9e4-4aa0-a1a3-3ad59224d7df"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['subject06.normal.gif', 'subject07.surprised.gif', 'subject02.surprised.gif', 'subject09.noglasses.gif', 'subject07.sad.gif', 'subject08.happy.gif', 'subject06.wink.gif', 'subject14.centerlight.gif', 'subject04.happy.gif', 'subject15.wink.gif', 'subject06.noglasses.gif', 'subject13.rightlight.gif', 'subject14.happy.gif', 'subject05.noglasses.gif', 'subject01.glasses.gif', 'subject02.glasses.gif', 'subject15.happy.gif', 'subject05.normal.gif', 'subject03.rightlight.gif', 'subject12.wink.gif', 'subject06.rightlight.gif', 'subject15.centerlight.gif', 'subject12.centerlight.gif', 'subject07.centerlight.gif', 'subject04.glasses.gif', 'subject15.noglasses.gif', 'subject11.leftlight.gif', 'subject09.wink.gif', 'subject12.surprised.gif', 'subject09.happy.gif', 'subject10.normal.gif', 'subject03.wink.gif', 'subject07.rightlight.gif', 'subject08.wink.gif', 'subject02.noglasses.gif', 'subject13.happy.gif', 'subject11.centerlight.gif', 'subject11.sleepy.gif', 'subject04.centerlight.gif', 'subject02.normal.gif', 'subject13.centerlight.gif', 'subject12.leftlight.gif', 'subject13.glasses.gif', 'subject04.wink.gif', 'subject09.sleepy.gif', 'subject14.noglasses.gif', 'subject04.normal.gif', 'subject03.happy.gif', 'subject12.noglasses.gif', 'subject10.rightlight.gif', 'subject03.normal.gif', 'subject13.wink.gif', 'subject14.leftlight.gif', 'subject15.surprised.gif', 'subject03.sleepy.gif', 'subject15.leftlight.gif', 'subject04.sleepy.gif', 'subject10.sleepy.gif', 'subject02.sad.gif', 'subject09.glasses.gif', 'subject06.sleepy.gif', 'subject12.glasses.gif', 'subject15.sleepy.gif', 'subject05.rightlight.gif', 'subject05.leftlight.gif', 'subject09.surprised.gif', 'subject05.happy.gif', 'subject05.glasses.gif', 'subject05.wink.gif', 'subject07.glasses.gif', 'subject13.noglasses.gif', 'subject01.rightlight.gif', 'subject15.glasses.gif', 'subject02.wink.gif', 'subject11.surprised.gif', 'subject01.wink.gif', 'subject03.centerlight.gif', 'subject04.noglasses.gif', 'subject13.leftlight.gif', 'subject13.normal.gif', 'subject15.normal.gif', 'subject06.sad.gif', 'subject12.happy.gif', 'subject14.wink.gif', 'subject14.glasses.gif', 'subject10.noglasses.gif', 'subject12.sleepy.gif', 'subject08.noglasses.gif', 'subject10.leftlight.gif', 'subject02.rightlight.gif', 'subject01.sad.gif', 'subject11.noglasses.gif', 'subject01.sleepy.gif', 'subject07.sleepy.gif', 'subject08.glasses.gif', 'subject14.rightlight.gif', 'subject09.normal.gif', 'subject04.sad.gif', 'subject11.normal.gif', 'subject07.normal.gif', 'subject12.sad.gif', 'subject07.noglasses.gif', 'subject14.surprised.gif', 'subject03.sad.gif', 'subject08.surprised.gif', 'subject05.centerlight.gif', 'subject01.noglasses.gif', 'subject13.surprised.gif', 'subject02.happy.gif', 'subject10.surprised.gif', 'subject01.leftlight.gif', 'subject08.leftlight.gif', 'subject11.wink.gif', 'subject01.surprised.gif', 'subject04.rightlight.gif', 'subject06.centerlight.gif', 'subject06.surprised.gif', 'subject03.noglasses.gif', 'subject10.glasses.gif', 'subject09.leftlight.gif', 'subject10.happy.gif', 'subject11.rightlight.gif', 'subject06.glasses.gif', 'subject03.surprised.gif', 'subject05.sad.gif', 'subject11.sad.gif', 'subject10.wink.gif', 'subject09.centerlight.gif', 'subject07.wink.gif', 'subject14.sleepy.gif', 'subject01.normal.gif', 'subject02.sleepy.gif', 'subject08.centerlight.gif', 'subject08.sleepy.gif', 'subject08.sad.gif']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image_data():\n",
        "  paths = [os.path.join('/content/yalefaces/train', f) for f in os.listdir('/content/yalefaces/train')]\n",
        "  #print(paths)\n",
        "  faces = []\n",
        "  ids = []\n",
        "  for path in paths:\n",
        "    imagem = Image.open(path).convert('L')\n",
        "    imagem_np = np.array(imagem,'uint8')\n",
        "    id = int(os.path.split(path)[1].split('.')[0].replace('subject',''))\n",
        "    ids.append(id)\n",
        "    faces.append(imagem_np)\n",
        "\n",
        "  return np.array(ids), faces\n",
        ""
      ],
      "metadata": {
        "id": "8rccSiJA-tDh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids, faces = get_image_data()"
      ],
      "metadata": {
        "id": "Iuvp7qnG-69K"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " lbph_classifier = cv2.face.LBPHFaceRecognizer_create()\n",
        " lbph_classifier.train(faces,ids)\n",
        " lbph_classifier.write('lbph_classifier.yml')"
      ],
      "metadata": {
        "id": "Vz2-q866BG87"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " lbph_classifier = cv2.face.LBPHFaceRecognizer_create()\n"
      ],
      "metadata": {
        "id": "zmQdDSW-ERah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Treinamento do classificador LBPH"
      ],
      "metadata": {
        "id": "DaUtLMSr-Jpx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Reconhecimento de faces"
      ],
      "metadata": {
        "id": "jdKayr91-O90"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mXanjZPj97XY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}